{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2e81b29c71eb2b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Task 2\n",
    "This serves as a template which will guide you through the implementation of this task. It is advised to first read the whole template and get a sense of the overall structure of the code before trying to fill in any of the TODO gaps.\n",
    "This is the jupyter notebook version of the template. For the python file version, please refer to the file `template_solution.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de347e31d213bd5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "First, we import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e071b8e282a8d6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T18:47:37.485752Z",
     "start_time": "2024-03-10T18:47:37.479263Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from fancyimpute import KNN, NuclearNormMinimization, SoftImpute, BiScaler\n",
    "import inspect\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, RBF, Matern, RationalQuadratic, Sum, Product, WhiteKernel, ExpSineSquared, ConstantKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Add any other imports you need here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f2086e18dd7b5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Data Loading\n",
    "TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "(and potentially change initialization of variables to accomodate how you deal with non-numeric data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "402e111cb0d70236",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matja\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matja\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Data used:  KNN_imputed_train_df\n",
      "X_train: (900, 9)\n",
      "y_train: (900,)\n",
      "X_test: (100, 9)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This loads the training and test data, preprocesses it, removes the NaN\n",
    "values and interpolates the missing data using imputation\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Compute\n",
    "----------\n",
    "X_train: matrix of floats, training input with features\n",
    "y_train: array of floats, training output with labels\n",
    "X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "\"\"\"\n",
    "# Load training data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "# print(\"Training data:\")\n",
    "# print(\"Shape:\", train_df.shape)\n",
    "# print(train_df.head(5))\n",
    "# print('\\n')\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "# print(\"Test data:\")\n",
    "# print(test_df.shape)\n",
    "# print(test_df.head(5))\n",
    "# print('\\n')\n",
    "\n",
    "\"\"\" \n",
    "One-Hot Encoding\n",
    "\"\"\"\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_df[['season']]))\n",
    "OH_cols_train.index = train_df.index\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out(['season'])\n",
    "# concatenate the new OneHotEncoded columns to the old ones \n",
    "leftover_cols_train = train_df.drop(['season'], axis=1)\n",
    "OH_X_train = pd.concat([OH_cols_train, leftover_cols_train], axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "# print(OH_X_train.head(5))\n",
    "\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.fit_transform(test_df[['season']]))\n",
    "OH_cols_test.index = test_df.index\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out(['season'])\n",
    "# concatenate the new OneHotEncoded columns to the old ones \n",
    "leftover_cols_test = test_df.drop(['season'], axis=1)\n",
    "OH_X_test = pd.concat([OH_cols_test, leftover_cols_test], axis=1)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "# print(OH_X_test.head(5))\n",
    "\n",
    "# train_df = OH_X_train\n",
    "# test_df = OH_X_test\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "MICE\n",
    "\"\"\"\n",
    "# Impute Training Data with MICE\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "imputed_train_df = imp.fit_transform(train_df.select_dtypes(include=[np.number]))\n",
    "imputed_train_df = pd.DataFrame(imputed_train_df, columns=train_df.select_dtypes(include=[np.number]).columns)\n",
    "# print(\"MICE Training data:\")\n",
    "# print(imputed_train_df.head(5))\n",
    "# print('\\n')\n",
    "\n",
    "# Impute Test Data with MICE\n",
    "imputed_test_df = imp.fit_transform(test_df.select_dtypes(include=[np.number]))\n",
    "imputed_test_df = pd.DataFrame(imputed_test_df, columns=test_df.select_dtypes(include=[np.number]).columns)\n",
    "# print(\"MICE Testing data:\")\n",
    "# print(imputed_test_df.head(5))\n",
    "# print('\\n')\n",
    "\n",
    "\"\"\" \n",
    "KNN\n",
    "\"\"\"\n",
    "# Impute Training Data with KNN\n",
    "KNN_imp = KNNImputer(n_neighbors=3, weights=\"uniform\")\n",
    "KNN_imputed_train_df = KNN_imp.fit_transform(train_df.select_dtypes(include=[np.number]))\n",
    "KNN_imputed_train_df = pd.DataFrame(KNN_imputed_train_df, columns=train_df.select_dtypes(include=[np.number]).columns)\n",
    "# print(\"KNN Training data:\")\n",
    "# print(KNN_imputed_train_df.head(5))\n",
    "# print('\\n')\n",
    "\n",
    "# Impute Test Data with KNN\n",
    "KNN_imputed_test_df = KNN_imp.fit_transform(test_df.select_dtypes(include=[np.number]))\n",
    "KNN_imputed_test_df = pd.DataFrame(KNN_imputed_test_df, columns=test_df.select_dtypes(include=[np.number]).columns)\n",
    "# print(\"KNN Test data:\")\n",
    "# print(KNN_imputed_test_df.head(5))\n",
    "# print('\\n')\n",
    "\n",
    "\"\"\"\n",
    "Transfer Imputed Data into Numpy\n",
    "\"\"\"\n",
    "# TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "def extract_params(imputed_traindata_df, imputed_testdata_df):\n",
    "    frame = inspect.currentframe()\n",
    "    try:\n",
    "        callers_local_vars = frame.f_back.f_locals.items()\n",
    "        df_name = next(name for name, val in callers_local_vars if val is imputed_traindata_df)\n",
    "        print(\"Imputed Data used: \", df_name)\n",
    "    finally:\n",
    "        del frame  # To avoid reference cycles\n",
    "        \n",
    "    y_train = imputed_traindata_df['price_CHF'].to_numpy()  # Convert 'price_CHF' column to numpy array\n",
    "    X_train = imputed_traindata_df.drop('price_CHF', axis=1).to_numpy()  # Convert remaining columns to numpy array\n",
    "    X_test = imputed_testdata_df.to_numpy()\n",
    "\n",
    "    return y_train, X_train, X_test\n",
    "\n",
    "y_train, X_train, X_test = extract_params(KNN_imputed_train_df, KNN_imputed_test_df)                                     \n",
    "print(\"X_train:\",  X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (X_test.shape[0] == 100), \"Invalid data shape\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02b4e7a-5348-4b67-a2a6-6753b1e5d943",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Modeling and Prediction\n",
    "TODO: Define the model and fit it using training data. Then, use test data to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb0d86b605f9813",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred (100,)\n",
      "[-2.52808123 -2.73060194 -2.66955418 -2.71576643 -2.56193499 -2.22947086\n",
      " -2.04363065 -1.76982229 -0.37267193  0.9266033   1.52843026  2.46263484\n",
      "  2.97648304  3.19005771  2.93103462  2.54489195  1.53548829  1.5127329\n",
      "  2.1845835   2.33201403  3.75041505  3.98009082  3.15427389  2.20402382\n",
      "  2.69967618  4.3817948   5.75234016  7.79233235  8.59337578  9.2850982\n",
      "  8.73157607  7.67758547  8.03912667  8.09531512  7.69546588  7.47845155\n",
      "  7.18047493  7.48433393  8.16370692  7.603452    7.97696686  7.74454684\n",
      "  7.78229465  7.83500889  7.46942541  7.97006217  7.22187428  7.48453291\n",
      "  7.81676517  7.68819536  8.44763528  8.38401857  8.09730763  8.21630324\n",
      "  8.55629813  9.37969214  8.1790876   8.07533615  7.09457336  6.69955939\n",
      "  6.32452358  5.41918679  5.30384308  5.11353697  4.89559246  4.85831463\n",
      "  4.7886502   4.54011     4.60350929  4.75552585  4.43496114  4.97558614\n",
      "  4.97768873  4.90007911  6.37124295  6.302576    7.27101148  7.64634086\n",
      "  7.9845162   7.96364045  8.49727621  8.88574752  7.33522845  8.77013391\n",
      "  8.41879783  8.66653541  8.81597636  8.41245996  7.62024295  7.98002833\n",
      "  8.2356015   7.813921    8.94965962  8.93739879  8.79177543  7.84902119\n",
      "  8.4300785   7.36383798  7.98991759  6.6715848 ]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This defines the model, fits training data and then does the prediction\n",
    "with the test data \n",
    "\n",
    "Parameters\n",
    "----------\n",
    "X_train: matrix of floats, training input with 10 features\n",
    "y_train: array of floats, training output\n",
    "X_test: matrix of floats: dim = (100, ?), test input with 10 features\n",
    "\n",
    "Compute\n",
    "----------\n",
    "y_test: array of floats: dim = (100,), predictions on test set\n",
    "\"\"\"\n",
    "#TODO: Define the model and fit it using training data. Then, use test data to make predictions\n",
    "\n",
    "gpr = GaussianProcessRegressor(kernel=Sum(Matern(), WhiteKernel()))\n",
    "gpr.fit(X_train, y_train)\n",
    "\n",
    "y_pred=gpr.predict(X_test)\n",
    "print(\"y_pred\", y_pred.shape)\n",
    "print(y_pred)\n",
    "\n",
    "assert y_pred.shape == (100,), \"Invalid data shape\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fef907-be15-4183-aeea-ca7a6b696b75",
   "metadata": {},
   "source": [
    "# Cross-validation for selection of best Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2aa24c2-6388-4e60-af4d-f90aeaefd08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " KF: 1 | score: 0.9908154213227873\n",
      " KF: 2 | score: 0.9639011494380465\n",
      " KF: 3 | score: 0.9891067249112022\n",
      " KF: 4 | score: 0.9606349178194932\n",
      " KF: 5 | score: 0.9724572862771002\n",
      " KF: 6 | score: 0.9757686107236504\n",
      " KF: 7 | score: 0.9821424166968546\n",
      " KF: 8 | score: 0.9411906073327535\n",
      " KF: 9 | score: 0.9842489492877704\n",
      "P2 score is  0.9733628982010732\n"
     ]
    }
   ],
   "source": [
    "## DIFFERENT KERNELS TESTED\n",
    "\n",
    "# MICE i = 10 | MICE i = 20 | KNN = 2 | KNN = 3 | MICE i = 10 HOE | MICE i = 20 HOE | KNN = 2 HOE | KNN = 3 HOE -->> accuracy on submission \n",
    "#kernel 1 = DotProduct                                                 - 0.999 | 0.833 | 0.827 | 0.831 | 0.999 | 0.999 |    -  |    -  ->> 0.079 \n",
    "#kernel 2 = RBF                                                        - 0.874 | -4.95 | -4.89 | -4.93 | 0.876 | 0.876 | -4.87 | -4.89 ->> 0.656 \n",
    "#kernel 3 = Matern                                                     - 0.907 | 0.949 | 0.946 | 0.948 | 0.895 | 0.895 | 0.953 | 0.951 ->> 0.780 \n",
    "#kernel 4 = Rat. Quad.                                                 - 0.896 | 0.957 | 0.953 | 0.956 | 0.891 | 0.891 | 0.958 | 0.954 ->> 0.919\n",
    "#kernel 5 = Sum(Matern(),WhiteKernel())                                - 0.911 | 0.970 | 0.969 | 0.973 | 0.909 | 0.909 | 0.971 | 0.971 ->>\n",
    "# submission:                                                                          | 0.9830| 0.9831|               | 0.9746| 0.9676\n",
    "#kernel 6 = Sum(RationalQuadratic(),WhiteKernel())                     - 0.906 | 0.974 | 0.964 | 0.969 | 0.909 | 0.909 | 0.970 | 0.970 ->>     \n",
    "# submission:                                                                          | 0.9826| 0.9830|               | 0.9733| 0.9676\n",
    "#kernel 7 = Sum(Product(ConstantKernel(1.0), RBF()), WhiteKernel())    - 0.999 | 0.977 | 0.970 | 0.976 | 0.999 | 0.999 | 0.960 | 0.966 ->>\n",
    "# submission:                                                                          | 0.9867| 0.9862|               | 0.9770| 0.9719\n",
    "#kernel 8 = Sum(Product(RationalQuadratic(), Matern()), WhiteKernel()) - 0.909 | 0.973 | 0.972 | 0.972 | 0.909 | 0.909 | 0.972 | 0.970 ->>\n",
    "# submission:                                                                          | 0.9815| 0.9823|               | 0.9745| 0.9674\n",
    "\"\"\"\n",
    "Comments:\n",
    "- risk of overfitting with product of kernel vs sum of kernels\n",
    "- WhiteKernel add noise, helping with data that isn't smooth. Summing this kernel with any other improves its K-fold r2score.\n",
    "- 0.999 scores are sketchy. Might submit one to see how it produces.\n",
    "- OneHot Encoder doesn't seem to improve MICE r2 score. It improves some of the KNN r2 scores.\n",
    "- kernels 5-8 seem most promising. Also important to observe each K-fold r2 score. Some have good overall score but one K-Fold r2 score < hard baseline\n",
    "- for submission, either ker5,6,8. I don't trust 7.\n",
    "- best so far: ker=5,6,8 for KNN = 3 (HOE optional)\n",
    "\"\"\"\n",
    "#gpr2 = GaussianProcessRegressor(kernel=Sum(Product(RationalQuadratic(), Matern()), WhiteKernel()))\n",
    "# pipeline = make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=RBF()))\n",
    "\n",
    "# Normalising data - unsure how to scale it back up after. Need to find way to rescale it for appropriate comparison to the submission.\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "n_folds = 9\n",
    "kf = KFold(n_folds)\n",
    "score = 0\n",
    "i = 0\n",
    "for train_data, test_data in kf.split(X_train):\n",
    "    i += 1\n",
    "    \n",
    "    X_train_KF, X_test_KF = X_train[train_data], X_train[test_data]\n",
    "    y_train_KF, y_test_KF = y_train[train_data], y_train[test_data]\n",
    "    \n",
    "    gpr.fit(X_train_KF, y_train_KF)\n",
    "    y_pred_KF, sigma = gpr.predict(X_test_KF, return_std=True)\n",
    "\n",
    "    # pipeline.fit(X_train_KF, y_train_KF)\n",
    "    # y_pred_KF = pipeline.predict(X_test_KF)\n",
    "\n",
    "    r2 = r2_score(y_test_KF, y_pred_KF)\n",
    "    score += r2\n",
    "    print(\" KF: {} | score: {}\".format(i,r2))\n",
    "\n",
    "score /= n_folds\n",
    "print(\"P2 score is \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c62e0cd4cec5a7e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Saving Results\n",
    "You don't have to change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382d87d2d67ddbdc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results file successfully generated!\n"
     ]
    }
   ],
   "source": [
    "dt = pd.DataFrame(y_pred) \n",
    "dt.columns = ['price_CHF']\n",
    "dt.to_csv('results.csv', index=False)\n",
    "print(\"\\nResults file successfully generated!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
